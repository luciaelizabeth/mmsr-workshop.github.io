# Submissions

We solicit papers on multimodal semantic representation, including but not limited to the following topics:
* Examination and interpretation of co-gestural speech and co-speech gesture;
* Semantic frameworks for individual linguistic co-modalities (e.g. gaze, facial expression);
* Formal representation of situated conversation and embodiment;
* Design and annotation of multimodal meaning representation (including extensions of existing semantic frameworks);
* Challenges in cross-lingual or cross-cultural multimodal representation;
* Challenges in semantic parsing of multimodal representation;
* Challenges in aligning co-modalities in formal representation and/or NLP;
* Discussion of criteria for evaluation of multimodal semantics;
* Position papers on meaning, language, and multimodality;
* Simulated agents that embody multimodal representations of common ground.

We strongly encourage students to submit to the workshop and will consider a student session depending on the number of submissions.

We will be using SoftConf to handle submissions.  Link coming soon!
